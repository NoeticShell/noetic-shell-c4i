#!/usr/bin/env python3
import feedparser, json, os
from c4i_logger import log_error, log_data

CACHE_FILE = os.path.expanduser("~/.c4i_alt_cache.json")

FEEDS = [
    ("ZeroHedge", "https://feeds.feedburner.com/zerohedge/feed"),
    ("RTWorld", "https://www.rt.com/rss/news/")
]

def fetch_next_alt_article():
    if os.path.exists(CACHE_FILE):
        with open(CACHE_FILE) as f:
            cache = json.load(f)
    else:
        cache = {"index": 0, "articles": [], "recent_articles": []}
    i = cache.get("index", 0) % len(FEEDS)
    name, url = FEEDS[i]
    article_text = None
    try:
        feed = feedparser.parse(url)
        if feed.entries:
            article = feed.entries[0]
            article_text = f"[{name}] {article.title}\n{article.link}\n{'-'*80}"
            cache["articles"].append(article_text)
    except Exception as e:
        article_text = f"[{name}] Error: {e}"
        log_error(name, str(e))
    if article_text:
        log_data(name, article_text)
        cache["recent_articles"].append(article_text)
    cache["index"] = i + 1
    output = None
    if len(cache["recent_articles"]) >= len(FEEDS):
        output = "\n".join(cache["recent_articles"])
        cache["recent_articles"] = []
    with open(CACHE_FILE, "w") as f:
        json.dump(cache, f)
    return output

if __name__ == "__main__":
    print(fetch_next_alt_article() or "(collecting alt-media articles...)")
